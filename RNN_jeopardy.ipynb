{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_jeopardy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clear21/Answer-Mashine/blob/master/RNN_jeopardy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y8vRqtp8X_AS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import urllib.request\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Dense , Activation , SimpleRNN , LSTM , Embedding\n",
        "from keras.models import Sequential\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1v3A-NDCbUVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#■関数\n",
        "\n",
        "#◆jsonファイルで保存\n",
        "#引数：保存対象オブジェクト、ファイル名(拡張子なし)\n",
        "def save_as_json(obj , fname):\n",
        "    json_fname_with_extension = fname + '.json'\n",
        "    fw = open(json_fname_with_extension , 'w')\n",
        "    json.dump(obj , fw , indent = 4)\n",
        "    fw.close()\n",
        "    files.download(json_fname_with_extension)\n",
        "\n",
        "#◆jsonファイルを取得\n",
        "#引数：対象ファイルのパス\n",
        "def import_json(fpass):\n",
        "    fr = open(fpass , 'r')\n",
        "    f = json.load(fr)\n",
        "    fr.close()\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsCMIaAUZJu7",
        "colab_type": "code",
        "outputId": "97fec755-5e4d-48e7-bf4c-1f4a86ee9d81",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "#QAデータセットの取得（JEOPARDY_CSV.csv）\n",
        "files.upload()\n",
        "\n",
        "# qa_data_url = r'https://drive.google.com/file/d/0BwT5wj_P7BKXUl9tOUJWYzVvUjA/view'\n",
        "# qa_file_name = 'JEOPARDY_CSV.csv'\n",
        "# urllib.request.urlretrieve(qa_data_url , qa_file_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-722401d0-8007-4da0-b8ea-80ae09329521\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-722401d0-8007-4da0-b8ea-80ae09329521\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving JEOPARDY_CSV.csv to JEOPARDY_CSV.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JQhL2tZRaHMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c7692928-f112-4ec5-b3d4-c5a9ac89b69a"
      },
      "cell_type": "code",
      "source": [
        "#QAデータをデータフレーム化（Question と Answer を使用する）\n",
        "qa_csv = r'JEOPARDY_CSV.csv'\n",
        "qa_df = pd.read_csv(qa_csv)[[' Question' , ' Answer']]\n",
        "\n",
        "#画像URLありの質問　＆　Answerが１wordでない　を除外\n",
        "qa_df = qa_df[~qa_df[' Question'].str.contains('<a href=')]\n",
        "print('画像URLありの質問' , '除外後' , len(qa_df))\n",
        "\n",
        "qa_df[' Answer'] = qa_df[' Answer'].str.strip()\n",
        "qa_df = qa_df[~qa_df[' Answer'].str.contains(' ' , na = True)]\n",
        "print('Answerが１wordでない' , '除外後' , len(qa_df))\n",
        "qa_df = qa_df.reset_index(drop = True)\n",
        "\n",
        "\n",
        "#テストのため、行数削減\n",
        "qa_df = qa_df[:100]\n",
        "qa_df = qa_df.reset_index(drop = True)\n",
        "\n",
        "print('len(qa_df)' , len(qa_df))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "画像URLありの質問 除外後 206407\n",
            "Answerが１wordでない 除外後 89070\n",
            "len(qa_df) 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "chlnIu1TaI6H",
        "colab_type": "code",
        "outputId": "2616bdaa-9fe6-4f2d-ab23-85c04f53365c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#■文字\n",
        "#関数：文字列→単価リスト（to_word_set～で使用）\n",
        "#第二引数：「Q」＝Question用処理、「A」＝Answer用処理\n",
        "def BK_sentence2wordlist(sentence , QorA):\n",
        "    sentence = str(sentence)\n",
        "    if QorA == 'Q':\n",
        "        return list(map(lambda x : x.lower() , re.sub(r' +' , ' ' , sentence.replace(',' , ' , ').replace('.' , ' . ').replace('?' , ' ? ').replace('\"' , '').replace('$' , ' $ ').replace('(' , ' ').replace(')' , ' '))))\n",
        "    elif QorA == 'A':\n",
        "        return sentence.lower()\n",
        "      \n",
        "#■単語\n",
        "#関数：文字列→単価リスト（to_word_set～で使用）\n",
        "#第二引数：「Q」＝Question用処理、「A」＝Answer用処理      \n",
        "def sentence2wordlist(sentence , QorA):\n",
        "    sentence = str(sentence)\n",
        "    if QorA == 'Q':\n",
        "        return list(map(lambda x : x.lower() , re.sub(r' +' , ' ' , sentence.replace(',' , ' , ').replace('.' , ' . ').replace('?' , ' ? ').replace('\"' , '').replace('$' , ' $ ').replace('(' , ' ').replace(')' , ' ')).split(' ')))\n",
        "    elif QorA == 'A':\n",
        "        return sentence.lower()\n",
        "\n",
        "#関数：文字列のリスト→単語の集合（重複無）※Question用\n",
        "def to_word_set_Qustion(sentence_list):\n",
        "    word_split_list = []\n",
        "    for sentence in sentence_list:\n",
        "        word_split_list += sentence2wordlist(sentence , 'Q')\n",
        "    return set(word_split_list)\n",
        "\n",
        "#関数：文字列のリスト→単語の集合（重複無）※Answer用\n",
        "def to_word_set_Answer(sentence_list):\n",
        "    word_split_list = []\n",
        "    for sentence in sentence_list:    \n",
        "        word_split_list.append(sentence2wordlist(sentence , 'A'))\n",
        "    return set(word_split_list)\n",
        "  \n",
        "#単語辞書作成\n",
        "#--単語一覧\n",
        "q_word_set = to_word_set_Qustion(qa_df[' Question'])\n",
        "a_word_set = to_word_set_Answer(qa_df[' Answer'])\n",
        "\n",
        "# word_set = q_word_set | a_word_set\n",
        "# del q_word_set , a_word_set\n",
        "\n",
        "#Q用：word2id_q、id2word_q　　A用：word2id_a、id2word_a\n",
        "#--Q用\n",
        "word_list_q = sorted(list(q_word_set))\n",
        "word2id_q = {word_list_q[i] : i for i in range(len(word_list_q))}\n",
        "id2word_q = {i : word_list_q[i] for i in range(len(word_list_q))}\n",
        "\n",
        "del q_word_set , word_list_q\n",
        "\n",
        "#--A用\n",
        "word_list_a = sorted(list(a_word_set))\n",
        "word2id_a = {word_list_a[i] : i for i in range(len(word_list_a))}\n",
        "id2word_a = {i : word_list_a[i] for i in range(len(word_list_a))}\n",
        "\n",
        "del a_word_set , word_list_a\n",
        "\n",
        "print('word2id_q' , len(word2id_q))\n",
        "print('word2id_a' , len(word2id_a))\n",
        "\n",
        "# word_list = sorted(list(word_set))\n",
        "# word2id = {word_list[i] : i for i in range(len(word_list))}\n",
        "# id2word = {i : word_list[i] for i in range(len(word_list))}\n",
        "# del word_set , word_list"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word2id_q 706\n",
            "word2id_a 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cz7RmWQ8dRY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14433
        },
        "outputId": "9425a3c5-9e15-47cc-e164-494038d6eae2"
      },
      "cell_type": "code",
      "source": [
        "#モデルの型\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "SEQLEN = 10\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "VOCAB_SIZE = len(word2id_q)\n",
        "EMBED_SIZE = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE\n",
        "                   , output_dim = EMBED_SIZE\n",
        "                   , embeddings_initializer = 'glorot_uniform'\n",
        "                   , input_length = SEQLEN))\n",
        "# model.add(SimpleRNN(HIDDEN_SIZE \n",
        "#                     , return_sequences = False\n",
        "#                     , stateful = False\n",
        "#                     #, batch_input_shape = (BATCH_SIZE , None , len(word2id_q)))\n",
        "#                     , input_shape = (None , len(word2id_q)))\n",
        "#                    )\n",
        "model.add(LSTM(HIDDEN_SIZE \n",
        "                     , return_sequences = False \n",
        "                     , input_shape = (None , len(word2id_q))))\n",
        "model.add(Dense(len(word2id_a)))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\" , optimizer = \"rmsprop\")\n",
        "\n",
        "#入力値として、各Questionに対して、SEQLEN文字ずつ区切ったものを作成し、Answerをラベルとする。\n",
        "one_fit_qa_num = 1\n",
        "\n",
        "word_split_question_list = []\n",
        "word_split_answer_list = []\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "#テスト\n",
        "for test_no in range(32):\n",
        "    for qa_no in range(len(qa_df)):\n",
        "\n",
        "        #テスト\n",
        "        print('■' * 10 , 'qa_no :' , qa_no)\n",
        "        if qa_no >= 5:\n",
        "            break\n",
        "\n",
        "        word_split_question_list.append( sentence2wordlist(qa_df[' Question'][qa_no] , 'Q') )\n",
        "        word_split_answer_list.append( sentence2wordlist(qa_df[' Answer'][qa_no] , 'A') )\n",
        "\n",
        "        if ((0 if one_fit_qa_num == 1 else qa_no % (one_fit_qa_num - 1)) == 0 or qa_no == len(qa_df) - 1) and (True if one_fit_qa_num == 1 else qa_no != 0) :\n",
        "            #入力用\n",
        "            word_per_SEQLEN = []\n",
        "            #ラベル\n",
        "            y = []\n",
        "\n",
        "            for word_split_question , word_split_answer in zip(word_split_question_list , word_split_answer_list):\n",
        "                append_y_size = 0\n",
        "\n",
        "                #入力\n",
        "                if (len(word_split_question) - SEQLEN + 1) > 0:\n",
        "                    for i in range(len(word_split_question) - SEQLEN + 1):\n",
        "                        word_per_SEQLEN.append(word_split_question[i : i + SEQLEN])\n",
        "                        append_y_size += 1\n",
        "                else :\n",
        "                    word_per_SEQLEN.append(word_split_question + ['' for i in range(SEQLEN - len(word_split_question))])\n",
        "                    append_y_size += 1\n",
        "\n",
        "                #ラベル\n",
        "                y = y + [[1 if j == word2id_a[word_split_answer] else 0 for j in range(len(word2id_a))] for i in range(append_y_size)]\n",
        "\n",
        "            #テスト\n",
        "#             print('■word_split_question_list')\n",
        "#             for i in range(len(word_split_question_list)):\n",
        "#                 print(word_split_question_list[i])\n",
        "#             else :\n",
        "#                 print()\n",
        "#             print('■word_per_SEQLEN')\n",
        "#             for i in range(len(word_per_SEQLEN)):\n",
        "#                 print(word_per_SEQLEN[i])\n",
        "#             else:\n",
        "#                 print()\n",
        "#             print('■y')\n",
        "#             for i in range(len(y)):\n",
        "#                 print('index :' , y[i].index(1))\n",
        "#             else:\n",
        "#                 print('word' , id2word_a[y[i].index(1)])\n",
        "#                 print()\n",
        "\n",
        "            #※idが要素\n",
        "            X = np.zeros((len(word_per_SEQLEN) , SEQLEN) , dtype = np.int)\n",
        "            \n",
        "            #※idが要素\n",
        "            for i in range(len(word_per_SEQLEN)):\n",
        "                w_list = word_per_SEQLEN[i]\n",
        "                for j in range(SEQLEN):\n",
        "                    wid = word2id_q[w_list[j]]\n",
        "                    X[i , j] = wid\n",
        "  \n",
        "            #※one_hot作成\n",
        "            #X = np.zeros((len(word_per_SEQLEN) , SEQLEN , len(word2id_q)) , dtype = np.bool)             \n",
        "            \n",
        "            #※one_hot作成\n",
        "            #for i in range(len(word_per_SEQLEN)):\n",
        "                #w_list = word_per_SEQLEN[i]\n",
        "                #for j in range(SEQLEN):\n",
        "                    #wid = word2id_q[w_list[j]]\n",
        "                    #X[i , j , wid] = 1\n",
        "\n",
        "            #×　ラベルの値\n",
        "            #×　y = [[1 if j == word2id[word_split_answer] else 0 for j in range(len(word2id))] for i in range(len(word_per_SEQLEN))]  \n",
        "\n",
        "            #学習\n",
        "            print('BATCH_SIZE:' , BATCH_SIZE)\n",
        "            model.fit(np.array(X) , np.array(y) , batch_size = BATCH_SIZE , epochs = NUM_EPOCHS_PER_ITERATION , shuffle = True)\n",
        "\n",
        "            model.reset_states()            \n",
        "\n",
        "            #1学習の時間\n",
        "            end = datetime.now()\n",
        "            print('learn time:' , end - start)\n",
        "\n",
        "            #初期化\n",
        "            word_split_question_list = []\n",
        "            word_split_answer_list = []\n",
        "\n",
        "            start = datetime.now()\n",
        "\n",
        "            #if qa_no == (one_fit_qa_num - 1):\n",
        "                #print('X' , np.array(X).shape)\n",
        "                #print('y' , len(y))\n",
        "                #break"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 10, 64)            45184     \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 98)                12642     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 98)                0         \n",
            "=================================================================\n",
            "Total params: 156,642\n",
            "Trainable params: 156,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 4.5213\n",
            "learn time: 0:00:02.995339\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5347\n",
            "learn time: 0:00:00.104372\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4.6039\n",
            "learn time: 0:00:00.078490\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4.5234\n",
            "learn time: 0:00:00.149759\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4655\n",
            "learn time: 0:00:00.111571\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.2831\n",
            "learn time: 0:00:00.119611\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.7081\n",
            "learn time: 0:00:00.107997\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.8021\n",
            "learn time: 0:00:00.075043\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2339\n",
            "learn time: 0:00:00.176540\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2.7991\n",
            "learn time: 0:00:00.143784\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4992\n",
            "learn time: 0:00:00.129027\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8397\n",
            "learn time: 0:00:00.109263\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.9745\n",
            "learn time: 0:00:00.086000\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.2678\n",
            "learn time: 0:00:00.153434\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.9504\n",
            "learn time: 0:00:00.124134\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7672\n",
            "learn time: 0:00:00.110971\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6812\n",
            "learn time: 0:00:00.113790\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.6971\n",
            "learn time: 0:00:00.081527\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.1870\n",
            "learn time: 0:00:00.150112\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.5887\n",
            "learn time: 0:00:00.116410\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5634\n",
            "learn time: 0:00:00.128586\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5814\n",
            "learn time: 0:00:00.106188\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 2.3730\n",
            "learn time: 0:00:00.085214\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.1115\n",
            "learn time: 0:00:00.162438\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3887\n",
            "learn time: 0:00:00.112649\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9790\n",
            "learn time: 0:00:00.108834\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4525\n",
            "learn time: 0:00:00.113426\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.1599\n",
            "learn time: 0:00:00.076779\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7944\n",
            "learn time: 0:00:00.153009\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2014\n",
            "learn time: 0:00:00.108982\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4173\n",
            "learn time: 0:00:00.107928\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2217\n",
            "learn time: 0:00:00.116528\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.9822\n",
            "learn time: 0:00:00.089577\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.6805\n",
            "learn time: 0:00:00.162940\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9487\n",
            "learn time: 0:00:00.121467\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2266\n",
            "learn time: 0:00:00.158568\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9507\n",
            "learn time: 0:00:00.106505\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.7064\n",
            "learn time: 0:00:00.077432\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5203\n",
            "learn time: 0:00:00.150459\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7253\n",
            "learn time: 0:00:00.106798\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1205\n",
            "learn time: 0:00:00.115958\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4672\n",
            "learn time: 0:00:00.107652\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.5334\n",
            "learn time: 0:00:00.075005\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.4540\n",
            "learn time: 0:00:00.152276\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5259\n",
            "learn time: 0:00:00.131228\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0552\n",
            "learn time: 0:00:00.123924\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3419\n",
            "learn time: 0:00:00.106060\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.2403\n",
            "learn time: 0:00:00.084106\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.3113\n",
            "learn time: 0:00:00.151301\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3660\n",
            "learn time: 0:00:00.126487\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0654\n",
            "learn time: 0:00:00.111043\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1680\n",
            "learn time: 0:00:00.117692\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.1832\n",
            "learn time: 0:00:00.079868\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1667\n",
            "learn time: 0:00:00.148825\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2231\n",
            "learn time: 0:00:00.110607\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0287\n",
            "learn time: 0:00:00.110295\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1832\n",
            "learn time: 0:00:00.126109\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6713\n",
            "learn time: 0:00:00.091787\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1291\n",
            "learn time: 0:00:00.164255\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1151\n",
            "learn time: 0:00:00.116737\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0235\n",
            "learn time: 0:00:00.107872\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0471\n",
            "learn time: 0:00:00.117815\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5915\n",
            "learn time: 0:00:00.075983\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.4578\n",
            "learn time: 0:00:00.155636\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1051\n",
            "learn time: 0:00:00.105913\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0146\n",
            "learn time: 0:00:00.109195\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0920\n",
            "learn time: 0:00:00.116350\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3199\n",
            "learn time: 0:00:00.077889\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0317\n",
            "learn time: 0:00:00.146446\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0576\n",
            "learn time: 0:00:00.110042\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0070\n",
            "learn time: 0:00:00.125484\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0373\n",
            "learn time: 0:00:00.114454\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1494\n",
            "learn time: 0:00:00.075308\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0268\n",
            "learn time: 0:00:00.154669\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0221\n",
            "learn time: 0:00:00.105508\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0061\n",
            "learn time: 0:00:00.119202\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0233\n",
            "learn time: 0:00:00.106928\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0938\n",
            "learn time: 0:00:00.077613\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0387\n",
            "learn time: 0:00:00.150958\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0148\n",
            "learn time: 0:00:00.106383\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035\n",
            "learn time: 0:00:00.107558\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0159\n",
            "learn time: 0:00:00.107518\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0395\n",
            "learn time: 0:00:00.079250\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0094\n",
            "learn time: 0:00:00.178764\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066\n",
            "learn time: 0:00:00.126393\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0024\n",
            "learn time: 0:00:00.118154\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092\n",
            "learn time: 0:00:00.136355\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0136\n",
            "learn time: 0:00:00.085370\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0055\n",
            "learn time: 0:00:00.143146\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0038\n",
            "learn time: 0:00:00.110486\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "learn time: 0:00:00.110583\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0056\n",
            "learn time: 0:00:00.110289\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0048\n",
            "learn time: 0:00:00.075840\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0032\n",
            "learn time: 0:00:00.159618\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "learn time: 0:00:00.106743\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 8.5402e-04\n",
            "learn time: 0:00:00.146199\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "learn time: 0:00:00.133139\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0025\n",
            "learn time: 0:00:00.101682\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0019\n",
            "learn time: 0:00:00.179590\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "learn time: 0:00:00.110675\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.9168e-04\n",
            "learn time: 0:00:00.107993\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0017\n",
            "learn time: 0:00:00.121519\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0012\n",
            "learn time: 0:00:00.081607\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "learn time: 0:00:00.146431\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4596e-04\n",
            "learn time: 0:00:00.105671\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.9626e-04\n",
            "learn time: 0:00:00.109781\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.5910e-04\n",
            "learn time: 0:00:00.105916\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 6.2497e-04\n",
            "learn time: 0:00:00.106313\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.8252e-04\n",
            "learn time: 0:00:00.183774\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.5428e-04\n",
            "learn time: 0:00:00.138403\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.6746e-04\n",
            "learn time: 0:00:00.144644\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.4349e-04\n",
            "learn time: 0:00:00.108881\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 3.3863e-04\n",
            "learn time: 0:00:00.078328\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 3.2358e-04\n",
            "learn time: 0:00:00.148894\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.9627e-04\n",
            "learn time: 0:00:00.110370\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.0055e-05\n",
            "learn time: 0:00:00.109856\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.0242e-04\n",
            "learn time: 0:00:00.112151\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.9174e-04\n",
            "learn time: 0:00:00.077480\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.8565e-04\n",
            "learn time: 0:00:00.189084\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 1.1009e-04\n",
            "learn time: 0:00:00.169696\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.2567e-05\n",
            "learn time: 0:00:00.134977\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.7085e-04\n",
            "learn time: 0:00:00.108654\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.0524e-04\n",
            "learn time: 0:00:00.080460\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.0369e-04\n",
            "learn time: 0:00:00.150204\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3806e-05\n",
            "learn time: 0:00:00.109339\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.2789e-05\n",
            "learn time: 0:00:00.109923\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.6586e-05\n",
            "learn time: 0:00:00.112487\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 6.3260e-05\n",
            "learn time: 0:00:00.085605\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 6.0058e-05\n",
            "learn time: 0:00:00.153312\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.6988e-05\n",
            "learn time: 0:00:00.124063\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.9598e-05\n",
            "learn time: 0:00:00.152272\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5.5277e-05\n",
            "learn time: 0:00:00.147174\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 3.7220e-05\n",
            "learn time: 0:00:00.095968\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.5218e-05\n",
            "learn time: 0:00:00.170873\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.2357e-05\n",
            "learn time: 0:00:00.114757\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1903e-05\n",
            "learn time: 0:00:00.118443\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.2117e-05\n",
            "learn time: 0:00:00.109222\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.2429e-05\n",
            "learn time: 0:00:00.082073\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.0266e-05\n",
            "learn time: 0:00:00.152752\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3574e-05\n",
            "learn time: 0:00:00.113266\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1824e-06\n",
            "learn time: 0:00:00.109432\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8803e-05\n",
            "learn time: 0:00:00.111911\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 1.4203e-05\n",
            "learn time: 0:00:00.098643\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.1930e-05\n",
            "learn time: 0:00:00.196155\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.4205e-06\n",
            "learn time: 0:00:00.109237\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.3571e-06\n",
            "learn time: 0:00:00.111873\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1189e-05\n",
            "learn time: 0:00:00.108393\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 9.2132e-06\n",
            "learn time: 0:00:00.083164\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 7.0504e-06\n",
            "learn time: 0:00:00.150986\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.1748e-06\n",
            "learn time: 0:00:00.112828\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.7001e-06\n",
            "learn time: 0:00:00.108991\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.7733e-06\n",
            "learn time: 0:00:00.114559\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 5.9009e-06\n",
            "learn time: 0:00:00.076242\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.2234e-06\n",
            "learn time: 0:00:00.180008\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.1861e-06\n",
            "learn time: 0:00:00.131163\n",
            "■■■■■■■■■■ qa_no : 5\n",
            "■■■■■■■■■■ qa_no : 0\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7107e-06\n",
            "learn time: 0:00:00.114455\n",
            "■■■■■■■■■■ qa_no : 1\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2103e-06\n",
            "learn time: 0:00:00.108640\n",
            "■■■■■■■■■■ qa_no : 2\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 3.8658e-06\n",
            "learn time: 0:00:00.081550\n",
            "■■■■■■■■■■ qa_no : 3\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.5587e-06\n",
            "learn time: 0:00:00.158616\n",
            "■■■■■■■■■■ qa_no : 4\n",
            "BATCH_SIZE: 4\n",
            "Epoch 1/1\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.0211e-06\n",
            "learn time: 0:00:00.109912\n",
            "■■■■■■■■■■ qa_no : 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4vCf4oiIgBS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2f974aaa-d042-4067-ab17-596d3ed0ca66"
      },
      "cell_type": "code",
      "source": [
        "#■関数\n",
        "\n",
        "#※one_hot作成\n",
        "#wordのリスト　→　入力用行列（1 × 入力word数 × len(word2id_q)）\n",
        "#※各word が word2id_q に存在すること（＝絶対条件：小文字）\n",
        "def BK_create_X(word_list , word2id_q = word2id_q):\n",
        "    wid_list = [word2id_q[word] for word in word_list]\n",
        "    return_X = np.zeros((1 , len(word_list) , len(word2id_q)) , dtype = np.bool)\n",
        "    for j in range(len(wid_list)):\n",
        "        return_X[0 , j , wid_list[j]] = 1\n",
        "    return return_X\n",
        "\n",
        "#※単語idが要素\n",
        "#wordのリスト　→　入力用行列（1 × 入力word数 × len(word2id_q)）\n",
        "#※各word が word2id_q に存在すること（＝絶対条件：小文字）\n",
        "def create_X(word_list , word2id_q = word2id_q):\n",
        "    wid_list = [word2id_q[word] for word in word_list]\n",
        "    return_X = np.zeros((1 , len(word_list)) , dtype = int)\n",
        "    for j in range(len(word_list)):\n",
        "        return_X[0 , j] = wid_list[j]\n",
        "    return return_X\n",
        "\n",
        "#test_word_list = list('For the last 8 years of his life, Galileo was'.lower())\n",
        "#test_word_list = ['f', 'o', 'r', ' ', 't', 'h', 'e', ' ', 'l', 'a', 's', 't', ' ', '8', ' ', 'y', 'e', 'a', 'r', 's', ' ', 'o', 'f', ' ', 'h', 'i', 's', ' ', 'l', 'i', 'f', 'e', ' ', ',', ' ', 'g', 'a', 'l', 'i', 'l', 'e', 'o', ' ', 'w', 'a', 's', ' ', 'u', 'n', 'd', 'e', 'r', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'f', 'o', 'r', ' ', 'e', 's', 'p', 'o', 'u', 's', 'i', 'n', 'g', ' ', 't', 'h', 'i', 's', ' ', 'm', 'a', 'n', \"'\", 's', ' ', 't', 'h', 'e', 'o', 'r', 'y'] #copernicus\n",
        "#test_word_list = ['in', '1963', ',', 'live', 'on', 'the', 'art', 'linkletter', 'show', ',', 'this', 'company', 'served', 'its', 'billionth', 'burger'] #mcdonald's\n",
        "test_word_list = ['for', 'the', 'last', '8', 'years', 'of', 'his', 'life', ',', 'galileo', 'was', 'under', 'house', 'arrest', 'for', 'espousing', 'this', \"man's\", 'theory'] #copernicus\n",
        "#test_word_list = ['the', 'city', 'of', 'yuma', 'in', 'this', 'state', 'has', 'a', 'record', 'average', 'of', '4', ',', '055', 'hours', 'of', 'sunshine', 'each', 'year'] #arizona\n",
        "#test_word_list = ['a' , 'small' , 'demon' , ',' , 'or' , 'a' , 'mischievous' , 'child' , 'who' , 'might' , 'be' , 'a' , 'little' , 'demon'] #imp\n",
        "#test_word_list = ['in' , 'the' , 'mid-18th' , 'c' , '.' , 'mikhail' , 'lomonosov' , 'became' , 'the' , 'first' , 'scientist' , 'to' , 'record' , 'the' , 'freezing' , 'of' , 'this' , 'liquid' , 'metal'] #mercury\n",
        "\n",
        "print(test_word_list)\n",
        "\n",
        "n = 3\n",
        "\n",
        "test_X = create_X(test_word_list)\n",
        "print(test_X)\n",
        "test_X = np.array([test_X[0][n : n+SEQLEN]])\n",
        "\n",
        "print(test_X)\n",
        "\n",
        "# start_no = 0\n",
        "# test_X = create_X(test_word_list[start_no : start_no + SEQLEN])\n",
        "\n",
        "pred = model.predict(test_X , verbose = 0)[0]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['for', 'the', 'last', '8', 'years', 'of', 'his', 'life', ',', 'galileo', 'was', 'under', 'house', 'arrest', 'for', 'espousing', 'this', \"man's\", 'theory']\n",
            "[[270 623 363  52 696 448 312 375   5 277 665 652 321  96 270 237 629 401\n",
            "  626]]\n",
            "[[ 52 696 448 312 375   5 277 665 652 321]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtUs0DcvgEFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a5ff949b-2df9-4532-e582-d531789d7136"
      },
      "cell_type": "code",
      "source": [
        "out_top_n = 10\n",
        "\n",
        "enum_pred = list(enumerate(pred))\n",
        "enum_pred.sort(key = lambda x : -x[1])\n",
        "\n",
        "top_enum_pred = enum_pred[:out_top_n]\n",
        "for i in range(len(top_enum_pred)):\n",
        "    print((i+1) , '位' , id2word_a[top_enum_pred[i][0]] , top_enum_pred[i][1] )\n",
        "\n",
        "print(id2word_a[np.argmax(pred)])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 位 copernicus 0.9999988\n",
            "2 位 arizona 7.6019677e-07\n",
            "3 位 washington 3.2263526e-07\n",
            "4 位 mcdonald's 3.200813e-08\n",
            "5 位 enamel 4.838371e-09\n",
            "6 位 blossoms 3.550857e-09\n",
            "7 位 helen 3.325925e-09\n",
            "8 位 india 2.92704e-09\n",
            "9 位 geronimo 2.91934e-09\n",
            "10 位 speed 2.8340423e-09\n",
            "copernicus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XyYhWbzx_1oG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sykY_SwfMiLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1bJovLBa31o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1RU5P-GOHxzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#重み取得\n",
        "merge_layer = model.layers[0]\n",
        "#embed_model = merge_layer.layers[0]\n",
        "#word_embed_layer = word_model.layers[0]\n",
        "weights = merge_layer.get_weights()[0]\n",
        "\n",
        "pd.DataFrame(weights).to_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yEcnyKAFFVkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EXCYr1-FVgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e6eca62a-7e23-482a-f08f-d6efe502faa1"
      },
      "cell_type": "code",
      "source": [
        "qa_df.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
              "      <td>Copernicus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The city of Yuma in this state has a record av...</td>\n",
              "      <td>Arizona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
              "      <td>McDonald's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the winter of 1971-72, a record 1,122 inche...</td>\n",
              "      <td>Washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This company's Accutron watch, introduced in 1...</td>\n",
              "      <td>Bulova</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question      Answer\n",
              "0  For the last 8 years of his life, Galileo was ...  Copernicus\n",
              "1  The city of Yuma in this state has a record av...     Arizona\n",
              "2  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's\n",
              "3  In the winter of 1971-72, a record 1,122 inche...  Washington\n",
              "4  This company's Accutron watch, introduced in 1...      Bulova"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "BBHLDnCBHxvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        },
        "outputId": "79fc6770-035b-431f-cf7f-d7335617739c"
      },
      "cell_type": "code",
      "source": [
        "id2word_a"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\"aida\"',\n",
              " 1: '\"candyman\"',\n",
              " 2: '\"carmen\"',\n",
              " 3: '\"crazy\"',\n",
              " 4: '\"dune\"',\n",
              " 5: '\"electricity\"',\n",
              " 6: '\"fallin\\'\"',\n",
              " 7: '\"goose\"',\n",
              " 8: '\"greensleeves\"',\n",
              " 9: '\"honey\"',\n",
              " 10: '\"jabberwocky\"',\n",
              " 11: '\"layla\"',\n",
              " 12: '\"mandy\"',\n",
              " 13: '\"moondance\"',\n",
              " 14: '\"nevermore!\"',\n",
              " 15: '\"pagliacci\"',\n",
              " 16: '\"rigoletto\"',\n",
              " 17: '\"rope-a\"',\n",
              " 18: '\"scream\"',\n",
              " 19: '-1',\n",
              " 20: '1',\n",
              " 21: '1-900',\n",
              " 22: '100%',\n",
              " 23: '11',\n",
              " 24: '12',\n",
              " 25: '14',\n",
              " 26: '1865',\n",
              " 27: '1930s',\n",
              " 28: '1941',\n",
              " 29: '1944',\n",
              " 30: '1960',\n",
              " 31: '1970s',\n",
              " 32: '1972',\n",
              " 33: '1984',\n",
              " 34: '19th',\n",
              " 35: '2,070',\n",
              " 36: '20',\n",
              " 37: '21',\n",
              " 38: '24',\n",
              " 39: '26',\n",
              " 40: '3',\n",
              " 41: '35mm',\n",
              " 42: '360',\n",
              " 43: '4',\n",
              " 44: '48',\n",
              " 45: '5',\n",
              " 46: '6',\n",
              " 47: '750',\n",
              " 48: '8',\n",
              " 49: '84',\n",
              " 50: '911',\n",
              " 51: '98',\n",
              " 52: 'aaron',\n",
              " 53: 'abscam',\n",
              " 54: 'academia',\n",
              " 55: 'acadia',\n",
              " 56: 'acapulco',\n",
              " 57: 'accommodations',\n",
              " 58: 'accordion',\n",
              " 59: 'achievement',\n",
              " 60: 'acquired',\n",
              " 61: 'acura',\n",
              " 62: 'adenoids',\n",
              " 63: 'adieu',\n",
              " 64: 'adonis',\n",
              " 65: 'aerosmith',\n",
              " 66: 'aeschylus',\n",
              " 67: 'aesop',\n",
              " 68: 'afghanistan',\n",
              " 69: 'africa',\n",
              " 70: 'against',\n",
              " 71: 'agamemnon',\n",
              " 72: 'agriculture',\n",
              " 73: 'air',\n",
              " 74: 'airplanes',\n",
              " 75: 'alabama',\n",
              " 76: 'alaska',\n",
              " 77: 'albania',\n",
              " 78: 'albany',\n",
              " 79: 'albatross',\n",
              " 80: 'alcatraz',\n",
              " 81: 'alcohol',\n",
              " 82: 'algeria',\n",
              " 83: 'algiers',\n",
              " 84: 'alias',\n",
              " 85: 'alice',\n",
              " 86: 'alternative',\n",
              " 87: 'altitude',\n",
              " 88: \"alzheimer's\",\n",
              " 89: 'amber',\n",
              " 90: 'amblin',\n",
              " 91: 'amc',\n",
              " 92: 'amman',\n",
              " 93: 'amontillado',\n",
              " 94: 'amos',\n",
              " 95: 'amphitheatre',\n",
              " 96: 'amtrak',\n",
              " 97: 'amway',\n",
              " 98: 'anchorage',\n",
              " 99: 'anchors',\n",
              " 100: 'anchovies',\n",
              " 101: 'andorra',\n",
              " 102: 'andrew',\n",
              " 103: 'andromeda',\n",
              " 104: 'angels',\n",
              " 105: 'angiosperms',\n",
              " 106: 'angola',\n",
              " 107: 'anthracite',\n",
              " 108: 'anthropology',\n",
              " 109: 'ants',\n",
              " 110: 'apache',\n",
              " 111: 'apples',\n",
              " 112: 'appliqué',\n",
              " 113: 'apprentice',\n",
              " 114: 'apéritif',\n",
              " 115: 'arbitration',\n",
              " 116: 'archaic',\n",
              " 117: 'archimedes',\n",
              " 118: 'ares',\n",
              " 119: 'argon',\n",
              " 120: 'aristide',\n",
              " 121: 'aristophanes',\n",
              " 122: 'aristotle',\n",
              " 123: 'arizona',\n",
              " 124: 'armenia',\n",
              " 125: 'arms',\n",
              " 126: 'aspirin',\n",
              " 127: 'asteroids',\n",
              " 128: 'athena',\n",
              " 129: 'athens',\n",
              " 130: 'atlanta',\n",
              " 131: 'atlantic',\n",
              " 132: 'atlantis',\n",
              " 133: 'atms',\n",
              " 134: 'atoms',\n",
              " 135: 'atrium',\n",
              " 136: 'auctions',\n",
              " 137: 'augusta',\n",
              " 138: 'augustus',\n",
              " 139: 'austin',\n",
              " 140: 'australia',\n",
              " 141: 'auto',\n",
              " 142: 'autopilot',\n",
              " 143: 'avalanches',\n",
              " 144: 'avalon',\n",
              " 145: 'ayatollah',\n",
              " 146: 'aye-aye',\n",
              " 147: 'azerbaijan',\n",
              " 148: 'aéropostale',\n",
              " 149: 'babe',\n",
              " 150: 'babes',\n",
              " 151: 'babushka',\n",
              " 152: 'babylon',\n",
              " 153: 'bacon',\n",
              " 154: 'badgering',\n",
              " 155: 'badgers',\n",
              " 156: 'badminton',\n",
              " 157: 'baghdad',\n",
              " 158: 'bahrain',\n",
              " 159: 'balaam',\n",
              " 160: 'baltimore',\n",
              " 161: 'bambi',\n",
              " 162: 'bamm-bamm',\n",
              " 163: 'bananas',\n",
              " 164: 'band-aid',\n",
              " 165: 'bangkok',\n",
              " 166: 'bank',\n",
              " 167: 'barbara',\n",
              " 168: 'barcelona',\n",
              " 169: 'bard',\n",
              " 170: 'barney',\n",
              " 171: 'barnstormer',\n",
              " 172: 'barracuda',\n",
              " 173: 'basketball',\n",
              " 174: 'bass',\n",
              " 175: 'bat',\n",
              " 176: 'batman',\n",
              " 177: 'bausch',\n",
              " 178: 'be',\n",
              " 179: 'beadle',\n",
              " 180: 'beau',\n",
              " 181: 'bedbug',\n",
              " 182: 'beethoven',\n",
              " 183: 'beetle',\n",
              " 184: 'beginning',\n",
              " 185: 'beijing',\n",
              " 186: 'belfast',\n",
              " 187: 'belleview',\n",
              " 188: 'bellows',\n",
              " 189: 'belly',\n",
              " 190: 'belt',\n",
              " 191: 'ben-hur',\n",
              " 192: 'benedict',\n",
              " 193: 'benetton',\n",
              " 194: 'benson',\n",
              " 195: 'beowulf',\n",
              " 196: 'berkeley',\n",
              " 197: 'berlin',\n",
              " 198: 'bermuda',\n",
              " 199: 'bethesda',\n",
              " 200: 'betsy',\n",
              " 201: 'between',\n",
              " 202: 'bevy',\n",
              " 203: 'bible',\n",
              " 204: 'bilbao',\n",
              " 205: 'biofeedback',\n",
              " 206: 'bird',\n",
              " 207: 'birmingham',\n",
              " 208: 'birthright',\n",
              " 209: 'bishop',\n",
              " 210: 'bitte',\n",
              " 211: 'bittersweet',\n",
              " 212: 'black',\n",
              " 213: 'blackbeard',\n",
              " 214: 'blackjack',\n",
              " 215: 'blacksmith',\n",
              " 216: 'blagojevich',\n",
              " 217: 'blank',\n",
              " 218: 'blasters',\n",
              " 219: 'blimp',\n",
              " 220: 'bloom',\n",
              " 221: 'bloomsbury',\n",
              " 222: 'blossoms',\n",
              " 223: 'blueberries',\n",
              " 224: 'bob',\n",
              " 225: 'bocce',\n",
              " 226: 'boleslaw',\n",
              " 227: 'bolivia',\n",
              " 228: 'bologna',\n",
              " 229: 'bombs',\n",
              " 230: 'bonanza',\n",
              " 231: 'bones',\n",
              " 232: 'boniface',\n",
              " 233: 'bonn',\n",
              " 234: 'bonsai',\n",
              " 235: 'boobytrap',\n",
              " 236: 'boojum',\n",
              " 237: 'boondoggle',\n",
              " 238: 'booties',\n",
              " 239: 'bootleg',\n",
              " 240: 'borders',\n",
              " 241: 'boron',\n",
              " 242: 'boston',\n",
              " 243: 'botswana',\n",
              " 244: 'bowery',\n",
              " 245: 'bowls',\n",
              " 246: 'brains',\n",
              " 247: 'brandy',\n",
              " 248: 'brasilia',\n",
              " 249: 'brazil',\n",
              " 250: 'bread',\n",
              " 251: 'bread/dough',\n",
              " 252: 'breathless',\n",
              " 253: 'bridge',\n",
              " 254: 'brigadoon',\n",
              " 255: 'brilliantine',\n",
              " 256: 'brim',\n",
              " 257: 'bronte',\n",
              " 258: 'brooklyn',\n",
              " 259: 'brouhaha',\n",
              " 260: 'brussels',\n",
              " 261: 'brutus',\n",
              " 262: 'bucephalus',\n",
              " 263: 'bucharest',\n",
              " 264: 'buck',\n",
              " 265: 'bucket',\n",
              " 266: 'buddha',\n",
              " 267: 'buddhism',\n",
              " 268: 'buddy',\n",
              " 269: 'buick',\n",
              " 270: 'bulba',\n",
              " 271: 'bulgaria',\n",
              " 272: 'bullfighting',\n",
              " 273: 'bulova',\n",
              " 274: 'bumblebee',\n",
              " 275: 'bunker',\n",
              " 276: 'burbank',\n",
              " 277: 'burn',\n",
              " 278: 'burp',\n",
              " 279: 'busing',\n",
              " 280: 'butter',\n",
              " 281: 'butterflies',\n",
              " 282: 'butterscotch',\n",
              " 283: 'buttonhook',\n",
              " 284: 'byron',\n",
              " 285: 'c',\n",
              " 286: 'caboose',\n",
              " 287: 'cactus',\n",
              " 288: 'caiman',\n",
              " 289: 'cain',\n",
              " 290: 'cairo',\n",
              " 291: 'calcium',\n",
              " 292: 'calgary',\n",
              " 293: 'california',\n",
              " 294: 'caligula',\n",
              " 295: 'calliope',\n",
              " 296: 'camel',\n",
              " 297: 'cameos',\n",
              " 298: 'camouflage',\n",
              " 299: 'can-can',\n",
              " 300: 'canada',\n",
              " 301: 'canberra',\n",
              " 302: 'cancer',\n",
              " 303: 'cancun',\n",
              " 304: 'candles',\n",
              " 305: 'canola',\n",
              " 306: 'capitalism',\n",
              " 307: 'capricorn',\n",
              " 308: 'carbonara',\n",
              " 309: 'cardboard',\n",
              " 310: 'cardinals',\n",
              " 311: 'careless',\n",
              " 312: 'carmen',\n",
              " 313: 'carnegie',\n",
              " 314: 'carrie',\n",
              " 315: 'casablanca',\n",
              " 316: 'castle',\n",
              " 317: 'castor',\n",
              " 318: 'catalan',\n",
              " 319: 'categorizing',\n",
              " 320: 'caviar',\n",
              " 321: 'cbs',\n",
              " 322: 'certs',\n",
              " 323: 'cervantes',\n",
              " 324: 'ceviche',\n",
              " 325: 'chamber',\n",
              " 326: 'chaparral',\n",
              " 327: 'chariots',\n",
              " 328: 'charlatan',\n",
              " 329: 'charleston',\n",
              " 330: 'charlotte',\n",
              " 331: 'chateau',\n",
              " 332: 'chattanooga',\n",
              " 333: 'chatter',\n",
              " 334: 'cheaters',\n",
              " 335: 'chechnya',\n",
              " 336: 'cheekbones',\n",
              " 337: 'cheese',\n",
              " 338: 'chekhov',\n",
              " 339: 'cherries',\n",
              " 340: 'cherry',\n",
              " 341: 'chess',\n",
              " 342: 'chestnuts',\n",
              " 343: 'cheyenne',\n",
              " 344: 'chicago',\n",
              " 345: 'chicanery',\n",
              " 346: 'children',\n",
              " 347: 'chile',\n",
              " 348: 'china',\n",
              " 349: 'chinoisserie',\n",
              " 350: 'chinook',\n",
              " 351: 'chivalry',\n",
              " 352: 'chlorine',\n",
              " 353: 'chock',\n",
              " 354: 'chocolate',\n",
              " 355: 'cholesterol',\n",
              " 356: 'chopin',\n",
              " 357: 'chopsticks',\n",
              " 358: 'christmas',\n",
              " 359: 'chrysler',\n",
              " 360: 'chunky',\n",
              " 361: 'churchill',\n",
              " 362: 'cia',\n",
              " 363: 'citigroup',\n",
              " 364: 'clarinet',\n",
              " 365: 'claudius',\n",
              " 366: 'clemens',\n",
              " 367: 'cleopatra',\n",
              " 368: 'cleveland',\n",
              " 369: 'clever',\n",
              " 370: 'cloister',\n",
              " 371: 'clone',\n",
              " 372: 'clonehenge',\n",
              " 373: 'cnn',\n",
              " 374: 'coachella',\n",
              " 375: 'coat',\n",
              " 376: 'cochise',\n",
              " 377: 'cochlear',\n",
              " 378: 'cocktail',\n",
              " 379: 'codeine',\n",
              " 380: 'coldplay',\n",
              " 381: 'collage',\n",
              " 382: 'colorado',\n",
              " 383: 'coma',\n",
              " 384: 'complex',\n",
              " 385: 'concord',\n",
              " 386: 'connecticut',\n",
              " 387: 'constant',\n",
              " 388: 'constantine',\n",
              " 389: 'contacts',\n",
              " 390: 'context',\n",
              " 391: 'continuity',\n",
              " 392: 'contra',\n",
              " 393: 'convicts/prisoners',\n",
              " 394: 'copenhagen',\n",
              " 395: 'copernicus',\n",
              " 396: 'coppertone',\n",
              " 397: 'corinth',\n",
              " 398: 'corn',\n",
              " 399: 'corning',\n",
              " 400: 'cornucopia',\n",
              " 401: 'cornwallis',\n",
              " 402: 'corolla',\n",
              " 403: 'correct',\n",
              " 404: 'corsica',\n",
              " 405: 'cortex',\n",
              " 406: 'couple',\n",
              " 407: 'couplets',\n",
              " 408: 'cowboy',\n",
              " 409: 'cozy',\n",
              " 410: 'crane',\n",
              " 411: 'crater',\n",
              " 412: 'crayfish',\n",
              " 413: 'crazy',\n",
              " 414: 'creationism',\n",
              " 415: 'crest',\n",
              " 416: 'crochet',\n",
              " 417: 'crocodile',\n",
              " 418: 'croesus',\n",
              " 419: 'cross-country',\n",
              " 420: 'croupier',\n",
              " 421: 'croutons',\n",
              " 422: 'crows',\n",
              " 423: 'crusades',\n",
              " 424: 'crust',\n",
              " 425: 'cryogenics',\n",
              " 426: 'crystal',\n",
              " 427: 'crêpes',\n",
              " 428: 'cuba',\n",
              " 429: 'cuisine',\n",
              " 430: 'cuneiform',\n",
              " 431: 'currant',\n",
              " 432: 'custard',\n",
              " 433: 'cyprus',\n",
              " 434: 'cyrillic',\n",
              " 435: 'czechoslovakia',\n",
              " 436: 'da',\n",
              " 437: 'daiquiri',\n",
              " 438: 'dallas',\n",
              " 439: 'dames',\n",
              " 440: 'dams',\n",
              " 441: 'dance',\n",
              " 442: 'danish',\n",
              " 443: 'dannon',\n",
              " 444: 'dante',\n",
              " 445: 'dartmouth',\n",
              " 446: 'dave',\n",
              " 447: 'debates',\n",
              " 448: 'decameron',\n",
              " 449: 'decanting',\n",
              " 450: 'decker',\n",
              " 451: 'decoy',\n",
              " 452: 'deified',\n",
              " 453: 'delta',\n",
              " 454: 'democracy',\n",
              " 455: 'denmark',\n",
              " 456: 'desdemona',\n",
              " 457: 'destruction',\n",
              " 458: 'deus',\n",
              " 459: 'devious',\n",
              " 460: 'devo',\n",
              " 461: 'diaghilev',\n",
              " 462: 'diamond',\n",
              " 463: 'diamonds',\n",
              " 464: 'dictionary',\n",
              " 465: 'diller',\n",
              " 466: 'dimensions',\n",
              " 467: 'diner',\n",
              " 468: 'dingo',\n",
              " 469: 'dinka',\n",
              " 470: 'dinosaur',\n",
              " 471: 'discovery',\n",
              " 472: 'disney',\n",
              " 473: 'divan',\n",
              " 474: 'dj',\n",
              " 475: 'do-re-mi',\n",
              " 476: 'dodge',\n",
              " 477: 'donatello',\n",
              " 478: 'doppler',\n",
              " 479: 'dora',\n",
              " 480: 'dorrit',\n",
              " 481: 'double',\n",
              " 482: 'doug',\n",
              " 483: 'dovetail',\n",
              " 484: 'down',\n",
              " 485: 'dramamine',\n",
              " 486: 'dreadlocks',\n",
              " 487: 'drew',\n",
              " 488: 'dribbling',\n",
              " 489: 'driver',\n",
              " 490: 'dronehenge',\n",
              " 491: 'drooling',\n",
              " 492: 'dublin',\n",
              " 493: 'dumas',\n",
              " 494: 'dune',\n",
              " 495: 'dutch',\n",
              " 496: 'eagle',\n",
              " 497: 'ear',\n",
              " 498: 'earn/urn',\n",
              " 499: 'earth',\n",
              " 500: 'earthquakes',\n",
              " 501: 'eat',\n",
              " 502: 'ebay',\n",
              " 503: 'ecru',\n",
              " 504: 'eden',\n",
              " 505: 'edinburgh',\n",
              " 506: 'edison',\n",
              " 507: 'edward',\n",
              " 508: 'effervescent',\n",
              " 509: 'eggplant',\n",
              " 510: 'eggs',\n",
              " 511: 'egomania',\n",
              " 512: 'egypt',\n",
              " 513: 'eighteen',\n",
              " 514: 'eighth',\n",
              " 515: 'eisenhower',\n",
              " 516: 'electra',\n",
              " 517: 'elephants',\n",
              " 518: 'elijah',\n",
              " 519: 'elk',\n",
              " 520: 'elkhound',\n",
              " 521: 'elvis',\n",
              " 522: 'eminem',\n",
              " 523: 'emu',\n",
              " 524: 'enamel',\n",
              " 525: 'endorphins',\n",
              " 526: 'endymion',\n",
              " 527: 'enewetak',\n",
              " 528: 'england',\n",
              " 529: 'ensenada',\n",
              " 530: 'episcopal',\n",
              " 531: 'era',\n",
              " 532: 'eskimos',\n",
              " 533: 'esmeralda',\n",
              " 534: 'esprit',\n",
              " 535: 'estrogen',\n",
              " 536: 'ethanol',\n",
              " 537: 'ethiopia',\n",
              " 538: 'evangeline',\n",
              " 539: 'evita',\n",
              " 540: 'excalibur',\n",
              " 541: 'exceed',\n",
              " 542: 'ezra',\n",
              " 543: 'fad',\n",
              " 544: 'fairbanks',\n",
              " 545: 'fairway',\n",
              " 546: 'faith',\n",
              " 547: 'fala',\n",
              " 548: 'familiar',\n",
              " 549: 'fantasia',\n",
              " 550: 'fat',\n",
              " 551: 'faulkner',\n",
              " 552: 'fergie',\n",
              " 553: 'fermions',\n",
              " 554: 'festoon',\n",
              " 555: 'fever',\n",
              " 556: 'finian',\n",
              " 557: 'finland',\n",
              " 558: 'finnish',\n",
              " 559: 'first',\n",
              " 560: 'fish',\n",
              " 561: 'fisher-price',\n",
              " 562: 'flag',\n",
              " 563: 'flamingo',\n",
              " 564: 'flattery',\n",
              " 565: 'flexible',\n",
              " 566: 'florence',\n",
              " 567: 'florida',\n",
              " 568: 'flounder',\n",
              " 569: 'folsom',\n",
              " 570: 'fondue',\n",
              " 571: 'ford',\n",
              " 572: 'foreigner',\n",
              " 573: 'forklifts',\n",
              " 574: 'four',\n",
              " 575: 'fourth',\n",
              " 576: 'fraction',\n",
              " 577: 'france',\n",
              " 578: 'frasier',\n",
              " 579: 'fraternity',\n",
              " 580: 'frau',\n",
              " 581: 'french',\n",
              " 582: 'fuji',\n",
              " 583: 'fx',\n",
              " 584: 'gabriel',\n",
              " 585: 'gaelic',\n",
              " 586: 'galileo',\n",
              " 587: 'gang',\n",
              " 588: 'garfield',\n",
              " 589: 'garlic',\n",
              " 590: 'gaseous',\n",
              " 591: 'gemini',\n",
              " 592: 'gendarmes',\n",
              " 593: 'geneva',\n",
              " 594: 'georgetown',\n",
              " 595: 'georgia',\n",
              " 596: 'german',\n",
              " 597: 'germany',\n",
              " 598: 'geronimo',\n",
              " 599: 'gestalt',\n",
              " 600: 'gettysburg',\n",
              " 601: 'giant',\n",
              " 602: 'gibbons',\n",
              " 603: 'gibraltar',\n",
              " 604: 'gilgamesh',\n",
              " 605: 'gingrich',\n",
              " 606: 'gloves',\n",
              " 607: 'godless',\n",
              " 608: 'gold',\n",
              " 609: 'golf',\n",
              " 610: 'goliath',\n",
              " 611: 'gomez',\n",
              " 612: 'gondolas',\n",
              " 613: 'goodyear',\n",
              " 614: 'google',\n",
              " 615: 'gorbachev',\n",
              " 616: 'gorilla',\n",
              " 617: 'gout',\n",
              " 618: 'governess',\n",
              " 619: 'governor',\n",
              " 620: 'grand',\n",
              " 621: 'grape',\n",
              " 622: 'grapefruit',\n",
              " 623: 'graph',\n",
              " 624: 'graphite',\n",
              " 625: 'grappa',\n",
              " 626: 'gravity',\n",
              " 627: 'gray',\n",
              " 628: 'grease',\n",
              " 629: 'greece',\n",
              " 630: 'greek',\n",
              " 631: 'greenback',\n",
              " 632: 'greenland',\n",
              " 633: 'greenpeace',\n",
              " 634: 'greensboro',\n",
              " 635: 'gregory',\n",
              " 636: 'grenada',\n",
              " 637: 'grenadine',\n",
              " 638: 'gretel',\n",
              " 639: 'gridiron',\n",
              " 640: 'grim',\n",
              " 641: 'group',\n",
              " 642: 'guadalajara',\n",
              " 643: 'guatemala',\n",
              " 644: 'guillotine',\n",
              " 645: 'guinness',\n",
              " 646: 'gullible',\n",
              " 647: 'gulliver',\n",
              " 648: 'gumbo',\n",
              " 649: 'gut',\n",
              " 650: 'gymnastics',\n",
              " 651: 'h2o',\n",
              " 652: 'haciendas',\n",
              " 653: 'hades',\n",
              " 654: 'hadrian',\n",
              " 655: 'haifa',\n",
              " 656: 'haiti',\n",
              " 657: 'half-life',\n",
              " 658: 'ham',\n",
              " 659: 'hamlet',\n",
              " 660: 'hanoi',\n",
              " 661: 'hanover',\n",
              " 662: 'happy',\n",
              " 663: 'hardness',\n",
              " 664: 'harlem',\n",
              " 665: 'harmonica',\n",
              " 666: 'harp',\n",
              " 667: 'harpies',\n",
              " 668: 'harps',\n",
              " 669: 'harvey',\n",
              " 670: 'hawaii',\n",
              " 671: 'hawk',\n",
              " 672: 'hawks',\n",
              " 673: 'hay',\n",
              " 674: 'hearsay',\n",
              " 675: 'heart',\n",
              " 676: 'heathers',\n",
              " 677: 'heaven',\n",
              " 678: 'hebrew',\n",
              " 679: 'heel',\n",
              " 680: 'heels',\n",
              " 681: 'helen',\n",
              " 682: 'helium',\n",
              " 683: 'hemingway',\n",
              " 684: 'hemlock',\n",
              " 685: 'hemming',\n",
              " 686: 'hercules',\n",
              " 687: 'herman',\n",
              " 688: 'hermes',\n",
              " 689: 'hero',\n",
              " 690: 'hershey',\n",
              " 691: \"hershey's\",\n",
              " 692: 'high-tops',\n",
              " 693: 'hilarious',\n",
              " 694: 'hindi',\n",
              " 695: 'hitchcock',\n",
              " 696: 'hockey',\n",
              " 697: 'honolulu',\n",
              " 698: 'hooters',\n",
              " 699: 'hope',\n",
              " 700: 'hornet',\n",
              " 701: 'horses',\n",
              " 702: 'hounds',\n",
              " 703: 'housewife',\n",
              " 704: 'hummingbirds',\n",
              " 705: 'hung',\n",
              " 706: 'hungarian',\n",
              " 707: 'hungary',\n",
              " 708: 'hunting',\n",
              " 709: 'hydrology',\n",
              " 710: 'hymn',\n",
              " 711: 'hypertension',\n",
              " 712: 'hyundai',\n",
              " 713: 'i',\n",
              " 714: 'iago',\n",
              " 715: 'ibex',\n",
              " 716: 'ibm',\n",
              " 717: 'ibn',\n",
              " 718: 'ibuprofen',\n",
              " 719: 'icarus',\n",
              " 720: 'ice-t',\n",
              " 721: 'iceland',\n",
              " 722: 'idaho',\n",
              " 723: 'identical',\n",
              " 724: 'identity',\n",
              " 725: 'illinois',\n",
              " 726: 'imminent',\n",
              " 727: 'imp',\n",
              " 728: 'impressionism',\n",
              " 729: 'incense',\n",
              " 730: 'inconvenient',\n",
              " 731: 'indemnity',\n",
              " 732: 'indestructible',\n",
              " 733: 'india',\n",
              " 734: 'indigenous',\n",
              " 735: 'indoctrination',\n",
              " 736: 'indonesia',\n",
              " 737: 'induction',\n",
              " 738: 'infinitive',\n",
              " 739: 'inflation',\n",
              " 740: 'ink',\n",
              " 741: 'innards',\n",
              " 742: 'innings',\n",
              " 743: 'innocent',\n",
              " 744: 'innuendo',\n",
              " 745: 'insignia',\n",
              " 746: 'insulin',\n",
              " 747: 'intelligence',\n",
              " 748: 'interview',\n",
              " 749: 'inuit',\n",
              " 750: 'invention',\n",
              " 751: 'inversion',\n",
              " 752: 'involuntary',\n",
              " 753: 'iodine',\n",
              " 754: 'iowa',\n",
              " 755: 'ipod',\n",
              " 756: 'iraq',\n",
              " 757: 'ireland',\n",
              " 758: 'iris',\n",
              " 759: 'iron',\n",
              " 760: 'isabella',\n",
              " 761: 'isaiah',\n",
              " 762: 'islam',\n",
              " 763: 'israel',\n",
              " 764: 'istanbul',\n",
              " 765: 'italy',\n",
              " 766: 'ivan',\n",
              " 767: 'ivory',\n",
              " 768: 'jack',\n",
              " 769: 'jacks',\n",
              " 770: 'jaguar',\n",
              " 771: 'jakarta',\n",
              " 772: 'jamaica',\n",
              " 773: 'jamboree',\n",
              " 774: 'james',\n",
              " 775: 'japan',\n",
              " 776: 'java',\n",
              " 777: 'jell-o',\n",
              " 778: 'jennifer',\n",
              " 779: 'jeopardy',\n",
              " 780: 'jeremiah',\n",
              " 781: 'jeremy',\n",
              " 782: 'jericho',\n",
              " 783: 'jerusalem',\n",
              " 784: 'jester',\n",
              " 785: 'jetsam',\n",
              " 786: 'jingo',\n",
              " 787: 'joanhenge',\n",
              " 788: 'jodhpurs',\n",
              " 789: 'john',\n",
              " 790: 'johnny',\n",
              " 791: 'johnson',\n",
              " 792: 'joints',\n",
              " 793: 'jojo',\n",
              " 794: 'joseph',\n",
              " 795: 'joshua',\n",
              " 796: 'joule',\n",
              " 797: 'jubilation',\n",
              " 798: 'jude',\n",
              " 799: 'judo',\n",
              " 800: 'junk',\n",
              " 801: 'junket',\n",
              " 802: 'jupiter',\n",
              " 803: 'justice',\n",
              " 804: 'k',\n",
              " 805: 'k2',\n",
              " 806: 'kalahari',\n",
              " 807: 'katherine',\n",
              " 808: 'kathmandu',\n",
              " 809: 'kenmore',\n",
              " 810: 'kentucky',\n",
              " 811: 'kenya',\n",
              " 812: 'kfc',\n",
              " 813: 'kibbutz',\n",
              " 814: 'kick',\n",
              " 815: 'kidneys',\n",
              " 816: 'killy',\n",
              " 817: 'kimchi',\n",
              " 818: 'king',\n",
              " 819: 'kipling',\n",
              " 820: 'knight',\n",
              " 821: 'knight-errant',\n",
              " 822: 'kodiak',\n",
              " 823: 'kohlrabi',\n",
              " 824: 'kohoutek',\n",
              " 825: 'koi',\n",
              " 826: 'krupp',\n",
              " 827: 'kugel',\n",
              " 828: 'l.a.',\n",
              " 829: 'lace',\n",
              " 830: 'lacrosse',\n",
              " 831: 'ladybugs',\n",
              " 832: 'lafayette',\n",
              " 833: 'lamb',\n",
              " 834: 'lambs',\n",
              " 835: 'lancelot',\n",
              " 836: 'land',\n",
              " 837: 'laos',\n",
              " 838: 'lapland',\n",
              " 839: 'lash',\n",
              " 840: 'latin',\n",
              " 841: 'latkes',\n",
              " 842: 'lax',\n",
              " 843: 'lay',\n",
              " 844: 'leap',\n",
              " 845: 'leather',\n",
              " 846: 'leaves',\n",
              " 847: 'legato',\n",
              " 848: 'legend',\n",
              " 849: 'legible',\n",
              " 850: 'legislative',\n",
              " 851: 'leisure',\n",
              " 852: 'lenin',\n",
              " 853: 'leo',\n",
              " 854: 'leotard',\n",
              " 855: 'leroy',\n",
              " 856: 'lesotho',\n",
              " 857: 'lesser',\n",
              " 858: 'levites',\n",
              " 859: 'lewis',\n",
              " 860: 'lexicon',\n",
              " 861: 'libido',\n",
              " 862: 'libra',\n",
              " 863: 'libraries',\n",
              " 864: 'life',\n",
              " 865: 'lifejackets',\n",
              " 866: 'lifetime',\n",
              " 867: 'light-heavyweight',\n",
              " 868: 'lightning',\n",
              " 869: 'lightweights',\n",
              " 870: 'limb',\n",
              " 871: 'limbo',\n",
              " 872: 'limburgh',\n",
              " 873: 'limestone',\n",
              " 874: 'lincoln',\n",
              " 875: 'link',\n",
              " 876: 'linux',\n",
              " 877: 'lipsticks',\n",
              " 878: 'listerine',\n",
              " 879: 'little',\n",
              " 880: 'liverpool',\n",
              " 881: 'lizards',\n",
              " 882: 'llamas',\n",
              " 883: 'lobster',\n",
              " 884: 'lockheed',\n",
              " 885: 'logos',\n",
              " 886: 'loki',\n",
              " 887: 'london',\n",
              " 888: 'lorna',\n",
              " 889: 'lothario',\n",
              " 890: 'louise',\n",
              " 891: 'louisiana',\n",
              " 892: 'lowell',\n",
              " 893: 'lox',\n",
              " 894: 'luciano',\n",
              " 895: 'lucy',\n",
              " 896: 'lupus',\n",
              " 897: 'lurch',\n",
              " 898: 'luxembourg',\n",
              " 899: 'luxor',\n",
              " 900: \"m&m's\",\n",
              " 901: 'm.d.',\n",
              " 902: 'maam',\n",
              " 903: 'macarthur',\n",
              " 904: 'macbeth',\n",
              " 905: 'macduff',\n",
              " 906: 'macgyver',\n",
              " 907: 'macrobiotic',\n",
              " 908: 'madagascar',\n",
              " 909: 'madeira',\n",
              " 910: 'madonna',\n",
              " 911: 'magellan',\n",
              " 912: 'magma',\n",
              " 913: 'magyar',\n",
              " 914: 'maids',\n",
              " 915: 'maine',\n",
              " 916: 'malaria',\n",
              " 917: 'malaysia',\n",
              " 918: 'male/mail',\n",
              " 919: 'mali',\n",
              " 920: 'mall',\n",
              " 921: 'mame',\n",
              " 922: 'mammoth',\n",
              " 923: 'manager',\n",
              " 924: 'manchester',\n",
              " 925: 'mandible',\n",
              " 926: 'mandolin',\n",
              " 927: 'manhattan',\n",
              " 928: 'manila',\n",
              " 929: 'manna',\n",
              " 930: 'mantis',\n",
              " 931: 'march',\n",
              " 932: 'marianne',\n",
              " 933: 'marionettes',\n",
              " 934: 'mars',\n",
              " 935: 'maryland',\n",
              " 936: 'massachusetts',\n",
              " 937: 'massage',\n",
              " 938: 'masts',\n",
              " 939: 'mathematics',\n",
              " 940: 'matthew',\n",
              " 941: 'mattingly',\n",
              " 942: 'matzah',\n",
              " 943: 'max',\n",
              " 944: 'may',\n",
              " 945: 'mayans',\n",
              " 946: 'mazda',\n",
              " 947: 'mcboing-boing',\n",
              " 948: 'mccartney',\n",
              " 949: 'mccloud',\n",
              " 950: \"mcdonald's\",\n",
              " 951: 'mcgill',\n",
              " 952: 'mci',\n",
              " 953: 'medea',\n",
              " 954: 'medellin',\n",
              " 955: 'meditate',\n",
              " 956: 'medvedev',\n",
              " 957: 'megalomania',\n",
              " 958: 'megan',\n",
              " 959: 'mekong',\n",
              " 960: 'melbourne',\n",
              " 961: 'memory',\n",
              " 962: 'mendel',\n",
              " 963: 'mendeleev',\n",
              " 964: 'mephistopheles',\n",
              " 965: 'mercury',\n",
              " 966: 'meringue',\n",
              " 967: 'merlin',\n",
              " 968: 'mesosphere',\n",
              " 969: 'metallica',\n",
              " 970: 'methane',\n",
              " 971: 'mexico',\n",
              " 972: 'michael',\n",
              " 973: 'michigan',\n",
              " 974: 'microwaves',\n",
              " 975: 'middlemarch',\n",
              " 976: 'mike',\n",
              " 977: 'milan',\n",
              " 978: 'milieu',\n",
              " 979: 'milkweed',\n",
              " 980: 'millay',\n",
              " 981: 'miltown',\n",
              " 982: 'mine',\n",
              " 983: 'minnesota',\n",
              " 984: 'minus',\n",
              " 985: 'mir',\n",
              " 986: 'mirage',\n",
              " 987: 'missouri',\n",
              " 988: 'mitosis',\n",
              " 989: 'mitsubishi',\n",
              " 990: 'mobil',\n",
              " 991: 'mobiles',\n",
              " 992: 'mobility',\n",
              " 993: 'mocha',\n",
              " 994: 'mockingbird',\n",
              " 995: 'moguls',\n",
              " 996: 'monaco',\n",
              " 997: 'money',\n",
              " 998: 'monk',\n",
              " 999: 'monroe',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "feGOBctyHxrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08df629a-c29d-416a-c38b-a82af8894979"
      },
      "cell_type": "code",
      "source": [
        "#Answer が 1word　でない　を除外する前\n",
        "print(len(word2id))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZKalmsdPLp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "974b5888-0b97-4707-b05f-e1df08aa87e2"
      },
      "cell_type": "code",
      "source": [
        "#Answer が 1word　でない　を除外した後\n",
        "print(len(word2id))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQkVRcIlek8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3d33e5da-753c-4255-d70d-20dc0e9fb9f0"
      },
      "cell_type": "code",
      "source": [
        "print(word2id['last'])\n",
        "print(word2id['8'])\n",
        "print(word2id['years'])\n",
        "print(word2id['of'])\n",
        "print(word2id['his'])\n",
        "\n",
        "\n",
        "print(word2id['galileo'])\n",
        "print(word2id['was'])\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4933\n",
            "604\n",
            "9254\n",
            "5997\n",
            "4220\n",
            "3724\n",
            "8958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tdK35PZbSHud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb00729e-1c74-42e2-eede-3d621081a45d"
      },
      "cell_type": "code",
      "source": [
        "n = len(qa_df) - 1\n",
        "\n",
        "print(qa_df[' Question'][n])\n",
        "print(qa_df[' Answer'][n])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the mid-18th c. Mikhail Lomonosov became the first scientist to record the freezing of this liquid metal\n",
            "mercury\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sfegL2VqGr-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        },
        "outputId": "98bf37d7-8d4d-42c2-bf52-01684b24935c"
      },
      "cell_type": "code",
      "source": [
        "a_word_set\n",
        "#word2id"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(omar) bradley',\n",
              " 'joseph smith',\n",
              " 'brussels',\n",
              " 'black death',\n",
              " 'jakarta',\n",
              " 'the new world',\n",
              " 'medellin',\n",
              " 'pods',\n",
              " 'jim carrey',\n",
              " 'ordinary people',\n",
              " 'california',\n",
              " 'drooling',\n",
              " 'soft',\n",
              " 'walt disney',\n",
              " 'milkweed',\n",
              " 'the nobel prizes',\n",
              " 'why does swiss cheese have holes?',\n",
              " 'the emerald city',\n",
              " '750',\n",
              " 'tnt',\n",
              " 'alexander graham bell',\n",
              " 'arms',\n",
              " 'bunker',\n",
              " 'old mother hubbard',\n",
              " 'rhizomes',\n",
              " '\\\\\"death on the nile\\\\\"',\n",
              " 'easter island',\n",
              " '\"rope-a\"',\n",
              " 'the indy 500',\n",
              " 'harold stratton',\n",
              " 'steadicam',\n",
              " 'tooth',\n",
              " 'coldplay',\n",
              " 'prologue',\n",
              " 'oh! calcutta!',\n",
              " 'carl sandburg',\n",
              " 'tiger woods',\n",
              " 'gloves',\n",
              " 'tee time',\n",
              " 'urban outfitters',\n",
              " 'psycho',\n",
              " \"the (runnin') rebels\",\n",
              " 'maids',\n",
              " 'kalahari',\n",
              " 'abraham lincoln',\n",
              " 'the canterbury tales',\n",
              " 'zoroastrianism',\n",
              " 'laugh track',\n",
              " 'lake champlain',\n",
              " 'hart to hart',\n",
              " 'chris rock',\n",
              " 'why does the snake crawl on the ground?',\n",
              " 'prince william',\n",
              " 'john cheever',\n",
              " '(frank) gehry',\n",
              " 'august wilson',\n",
              " '\"the village blacksmith\"',\n",
              " 'helen',\n",
              " '(art) garfunkel',\n",
              " 'balance beam',\n",
              " 'claude monet',\n",
              " 'the brain',\n",
              " 'ford',\n",
              " 'unicorn',\n",
              " 'fantasia',\n",
              " \"rice's vices\",\n",
              " 'willa cather',\n",
              " 'a pedestal',\n",
              " 'robinson crusoe',\n",
              " 'roald amundsen',\n",
              " 'henry james',\n",
              " 'the bus',\n",
              " 'cain',\n",
              " 'britney spears',\n",
              " 'ulysses s. grant',\n",
              " 'the joker',\n",
              " 'polyester',\n",
              " \"m&m's\",\n",
              " '\"i\\'ll be there\"',\n",
              " 'john c. frémont',\n",
              " 'italy',\n",
              " 'vincent van gogh',\n",
              " 'henry moore',\n",
              " 'decanting',\n",
              " 'gymnastics',\n",
              " 'the hoover dam',\n",
              " 'daisy hill puppy farm',\n",
              " 'the lungs',\n",
              " 'scared straight',\n",
              " 'gemini',\n",
              " 'february 14',\n",
              " 'hemingway',\n",
              " 'ply',\n",
              " 'spam',\n",
              " 'hawaii',\n",
              " 'the missouri',\n",
              " 'judi dench',\n",
              " 'jamaica',\n",
              " 'ivory',\n",
              " 'isaiah',\n",
              " 'the benjamins',\n",
              " 'saint augustine',\n",
              " 'beijing',\n",
              " 'garlic',\n",
              " 'your neck',\n",
              " 'rosie (roosevelt) grier',\n",
              " 'an american tragedy',\n",
              " 'moody blues',\n",
              " 'draw a circle',\n",
              " 'althea gibson',\n",
              " 'the 1990s',\n",
              " 'king',\n",
              " 'saigon',\n",
              " 'oksana baiul',\n",
              " 'angels',\n",
              " 'chile',\n",
              " 'lyndon johnson',\n",
              " 'the bridge',\n",
              " 'waterspouts',\n",
              " 'a kilt',\n",
              " 'the african queen (humphrey bogart & katharine hepburn)',\n",
              " 'sam houston',\n",
              " 'silver',\n",
              " 'charles lindbergh',\n",
              " 'batman',\n",
              " 'veni, vidi, vici (i came, i saw, i conquered)',\n",
              " 'mumbo-jumbo',\n",
              " 'ron burgundy',\n",
              " 'the sputnik launch',\n",
              " '-1',\n",
              " 'lizards',\n",
              " 'the \"mystery train\"',\n",
              " 'things with holes',\n",
              " 'mt. mckinley',\n",
              " 'mushrooms',\n",
              " 'philip roth',\n",
              " 'jacques chirac',\n",
              " 'poland',\n",
              " 'patrick leahy',\n",
              " 'bonn',\n",
              " 'south dakota',\n",
              " 'pizarro',\n",
              " 'proctor & gamble',\n",
              " 'speed',\n",
              " 'mammoth',\n",
              " 'lapland',\n",
              " 'anne hathaway',\n",
              " 'hannibal lecter',\n",
              " 'gingrich',\n",
              " 'andrew',\n",
              " 'blank',\n",
              " 'romulus & remus',\n",
              " 'icarus',\n",
              " 'jackson pollock',\n",
              " 'fourth',\n",
              " 'steinbeck',\n",
              " 'latin',\n",
              " '(2 of) robert de niro, al pacino, michael v. gazzo, & lee strasberg',\n",
              " 'the eggs',\n",
              " 'wigwams',\n",
              " 'the lion king',\n",
              " 'betty white',\n",
              " 'apple computer',\n",
              " 'zeus',\n",
              " 'rotisserie chicken',\n",
              " 'soda water',\n",
              " 'touched by an angel',\n",
              " '2,070',\n",
              " '(paul) bonwit',\n",
              " 'lifejackets',\n",
              " 'vince gill',\n",
              " 'sloop (pools)',\n",
              " 'their shoes',\n",
              " 'subway',\n",
              " 'a cote',\n",
              " 'communist sympathizer',\n",
              " 'hilary duff',\n",
              " 'stephen douglas',\n",
              " 'massachusetts',\n",
              " 'federal express',\n",
              " 'the theory of everything',\n",
              " 'hamlet',\n",
              " '(pierre de) fermat',\n",
              " 'maryland',\n",
              " 'london',\n",
              " 'pull it out from under him',\n",
              " 'the quakers',\n",
              " 'aéropostale',\n",
              " 'oldsmobile',\n",
              " 'constant',\n",
              " 'march',\n",
              " 'rigveda',\n",
              " 'saarinen',\n",
              " 'san jose',\n",
              " 'major barbara',\n",
              " 'clever',\n",
              " 'tube steak',\n",
              " 'the lionhearted',\n",
              " 'eskimos',\n",
              " 'oxford university',\n",
              " 'bullfighting',\n",
              " 'yellowstone',\n",
              " 'white belt',\n",
              " 'philip',\n",
              " 'eighteen',\n",
              " 'pepé le pew',\n",
              " 'edward kennedy',\n",
              " 'a bombshell',\n",
              " 'purdue',\n",
              " 't.s. eliot',\n",
              " 'h.j. heinz (heinz 57 varieties)',\n",
              " 'aspirin',\n",
              " 'alcohol',\n",
              " 'mountains',\n",
              " 'steven wright',\n",
              " 'the flea',\n",
              " 'churchill',\n",
              " 'dr. livingstone',\n",
              " 'beetle',\n",
              " 'a key club',\n",
              " 'prison break',\n",
              " 'from soup to nuts',\n",
              " 'alternative',\n",
              " '35mm',\n",
              " 'dj',\n",
              " 'the magic school bus',\n",
              " 'chopsticks',\n",
              " 'a carriage',\n",
              " '\"jane eyre\"',\n",
              " 'hanoi (vietnam)',\n",
              " 'types of plays',\n",
              " 'a fan',\n",
              " 'your shoes',\n",
              " 'pearl harbor',\n",
              " 'hanover',\n",
              " 'santa maria',\n",
              " 'mr. french',\n",
              " 'oahu',\n",
              " 'bowls',\n",
              " 'the lbj library',\n",
              " 'union station',\n",
              " 'world war i',\n",
              " 'norway and sweden',\n",
              " 'era',\n",
              " '(franklin) pierce',\n",
              " 'scotland',\n",
              " 'jericho',\n",
              " '(ty) cobb',\n",
              " 'bob dole',\n",
              " 'rhode island',\n",
              " 'eminem',\n",
              " 'joshua',\n",
              " 'crystal',\n",
              " 'stayed staid',\n",
              " 'ponehenge',\n",
              " 'oratory',\n",
              " 'k2',\n",
              " 'blue jay',\n",
              " 'guadalajara',\n",
              " 'cotton candy',\n",
              " 'beginning',\n",
              " 'edison',\n",
              " 'l.a. law',\n",
              " 'llamas',\n",
              " 'devils tower',\n",
              " 'mumbai',\n",
              " 'fairway',\n",
              " 'buddha',\n",
              " 'the high five',\n",
              " 'noticeable',\n",
              " 'the revolutionary war',\n",
              " '(rutherford b.) hayes',\n",
              " 'the flintstones',\n",
              " 'saint patrick',\n",
              " 'sunday',\n",
              " 'nairobi, kenya',\n",
              " 'decoy',\n",
              " 'richmond',\n",
              " '(aleksandr) pushkin',\n",
              " 'wonk (know)',\n",
              " 'blagojevich',\n",
              " 'oliver twist',\n",
              " 'lace',\n",
              " 'pericardium',\n",
              " 'the neverending story',\n",
              " 'autopilot',\n",
              " 'pigeon',\n",
              " 'san antonio',\n",
              " '\"it\\'s my life\"',\n",
              " 'skechers',\n",
              " 'manna',\n",
              " 'elisabeth shue',\n",
              " 'chicken scratches',\n",
              " 'george mcclellan',\n",
              " 'north',\n",
              " 'jacks',\n",
              " 'harrison ford',\n",
              " '(john) grisham',\n",
              " 'the sun',\n",
              " 'kenya',\n",
              " 'magic johnson',\n",
              " 'unintentional',\n",
              " 'neonatal',\n",
              " 'utah (great salt lake)',\n",
              " 'ho chi minh city (formerly saigon)',\n",
              " 'omaha',\n",
              " 'the wolf',\n",
              " 'oregon trail',\n",
              " 'wilt chamberlain',\n",
              " 'a rich witch',\n",
              " 'the mousetrap',\n",
              " 'austin',\n",
              " 'steve martini',\n",
              " 'the hudsucker proxy',\n",
              " 'an inchworm',\n",
              " 'brigadier general',\n",
              " 'ninety-nine',\n",
              " \"adam's rib\",\n",
              " 'myanmar (burma)',\n",
              " 'australian dollar',\n",
              " 'war and peace',\n",
              " 'indonesia',\n",
              " 'hunting',\n",
              " 'james',\n",
              " 'the salvation army',\n",
              " 'brigham young',\n",
              " 'amos (jam ostensibly)',\n",
              " 'new mexico',\n",
              " 'jean foucault',\n",
              " 'coma',\n",
              " 'general antonio lopez de santa ana',\n",
              " 'huey long',\n",
              " 'cairo',\n",
              " 'barcelona',\n",
              " 'gridiron',\n",
              " 'agatha christie',\n",
              " 'month',\n",
              " 'coachella',\n",
              " 'gettysburg',\n",
              " '(george herbert walker) bush',\n",
              " 'medvedev',\n",
              " 'john',\n",
              " 'spoon bread',\n",
              " 'sneeze',\n",
              " 'acadia',\n",
              " 'taekwondo',\n",
              " 'new zealand',\n",
              " 'job (mojo by)',\n",
              " \"martha's vineyard\",\n",
              " 'carbonara',\n",
              " 'july 1',\n",
              " 'soviet union & china',\n",
              " 'the muskrat',\n",
              " 'tori amos',\n",
              " 'couple',\n",
              " 'jim brown',\n",
              " 'methane',\n",
              " 'voting',\n",
              " 'jackie gleason',\n",
              " '1960',\n",
              " 'the temple of dendur',\n",
              " 'cholesterol',\n",
              " 'tennessee',\n",
              " 'yale',\n",
              " 'one-half',\n",
              " 'paul',\n",
              " 'identical',\n",
              " 'rosemary rogers',\n",
              " 'madeira',\n",
              " 'babe',\n",
              " 'crêpes',\n",
              " 'noah',\n",
              " 'circuit city',\n",
              " 'john brown',\n",
              " 'a (blood) clot',\n",
              " 'flamingo',\n",
              " 'a handstand',\n",
              " 'maroon 5',\n",
              " 'a semiconductor',\n",
              " 'hilarious',\n",
              " 'black hole',\n",
              " 'the tempest',\n",
              " 'meditate',\n",
              " 'ottoman empire',\n",
              " 'harry potter',\n",
              " 'eddie izzard',\n",
              " 'the roc',\n",
              " 'presto',\n",
              " 'hank williams, sr.',\n",
              " 'zenger',\n",
              " 'xylophone',\n",
              " 'strapping',\n",
              " 'lash',\n",
              " 'rocky',\n",
              " \"noah's ark\",\n",
              " 'perch',\n",
              " 'date of birth',\n",
              " 'limburgh',\n",
              " 'bruce springsteen',\n",
              " 'a drywaller',\n",
              " \"achilles' heel\",\n",
              " '\"electricity\"',\n",
              " 'little bighorn',\n",
              " 'taco',\n",
              " 'saint valentine',\n",
              " 'the cerebellum',\n",
              " 'coat',\n",
              " 'the nucleus',\n",
              " 'jane russell',\n",
              " 'william jennings bryan',\n",
              " '\"go bragh\"',\n",
              " '\"the king and i\"',\n",
              " 'toxicology',\n",
              " 'mike connors',\n",
              " 'a salt',\n",
              " 'the mexican hairless',\n",
              " 'the moonwalk',\n",
              " 'ludwig van beethoven',\n",
              " 'rupert grint',\n",
              " 'anchorage',\n",
              " 'prohibition',\n",
              " '(niels) bohr',\n",
              " 'bruno hauptmann',\n",
              " 'national geographic',\n",
              " 'ibm',\n",
              " 'wool',\n",
              " 'the \"rubber chicken\" circuit',\n",
              " 'balmoral castle',\n",
              " 'a coterie',\n",
              " 'daniel webster',\n",
              " 'a syllabus',\n",
              " 'fort sumter',\n",
              " 'laura ingalls wilder',\n",
              " 'sports illustrated',\n",
              " '\"god bless america\"',\n",
              " 'the accidental tourist',\n",
              " 'kidneys',\n",
              " \"bruce's juices\",\n",
              " 'stephen vincent benet',\n",
              " 'yerevan',\n",
              " 'scrabble',\n",
              " 'jeopardy',\n",
              " 'phil collins',\n",
              " '\"the picture of dorian gray\"',\n",
              " 'pegasus',\n",
              " \"mrs. o'leary's cow\",\n",
              " 'jerry west',\n",
              " 'atlas mountains',\n",
              " 'dramamine',\n",
              " 'the cheetah',\n",
              " 'benjamin disraeli',\n",
              " 'augusta',\n",
              " 'coppertone',\n",
              " 'tristan',\n",
              " 'pennsylvania',\n",
              " 'marilyn manson',\n",
              " 'a dense winter fog',\n",
              " 'pepperoni',\n",
              " 'festoon',\n",
              " 'sound',\n",
              " 'dorrit',\n",
              " 'the stone',\n",
              " 'devour flour',\n",
              " 'red heat',\n",
              " 'vietnam war',\n",
              " 'jerry lewis',\n",
              " 'wii',\n",
              " 'the great gatsby',\n",
              " '(reggie) jackson',\n",
              " 'philip seymour hoffman',\n",
              " 'the crucible',\n",
              " \"custer's last stand\",\n",
              " 'spinach',\n",
              " 'francis scott key',\n",
              " 'mumble',\n",
              " 'the new yorker',\n",
              " 'dance',\n",
              " 'jai alai',\n",
              " 'babylon',\n",
              " 'georgia',\n",
              " \"(lord) nelson's column\",\n",
              " 'mumps',\n",
              " 'the exorcist',\n",
              " 'fondue',\n",
              " '(wilt) chamberlain',\n",
              " 'tom hanks',\n",
              " 'dew (wed)',\n",
              " 'dave',\n",
              " 'chemical reactions',\n",
              " 'tickle us',\n",
              " 'doug',\n",
              " 'fisher-price',\n",
              " 'mao tse-tung',\n",
              " 'adonis',\n",
              " 'common sense',\n",
              " 'imp',\n",
              " 'the jazz singer',\n",
              " 'pulp fiction',\n",
              " 'aquarius (w.h. harrison, lincoln, mckinley & fdr were the presidents who died in office)',\n",
              " 'harriet beecher stowe',\n",
              " 'heart of darkness',\n",
              " 'a sequoia',\n",
              " 'ruthless',\n",
              " 'hungary',\n",
              " 'spain',\n",
              " 'taos, new mexico',\n",
              " 'atlantic',\n",
              " 'high-tops',\n",
              " 'ralph waldo emerson',\n",
              " 'dinner jacket',\n",
              " 'a leer',\n",
              " 'egypt',\n",
              " 'titans',\n",
              " 'tried & treed',\n",
              " 'thomas jefferson',\n",
              " 'debbie thomas',\n",
              " 'atms',\n",
              " 'carrie',\n",
              " 'geoffrey chaucer (the canterbury tales)',\n",
              " 'zarathustra',\n",
              " 'french horn',\n",
              " '(james) cook',\n",
              " 'the f.b.i.',\n",
              " 'air force',\n",
              " 'sausages',\n",
              " 'crusades',\n",
              " 'h&r block',\n",
              " 'libra',\n",
              " 'anton chekhov',\n",
              " 'mantis',\n",
              " 'bette midler',\n",
              " 'rings',\n",
              " 'noble gases',\n",
              " 'hockey',\n",
              " 'mike judge',\n",
              " 'florida',\n",
              " 'ontario',\n",
              " 'viacom',\n",
              " 'd.h. lawrence',\n",
              " 'bologna',\n",
              " 'pancakes',\n",
              " 'snoop doggy dogg',\n",
              " 'australia',\n",
              " 'i love you; you love me',\n",
              " 'el supremo',\n",
              " 'mendel',\n",
              " 'the denver broncos',\n",
              " 'u.n.c.l.e. (united network command for law and enforcement)',\n",
              " 'mary shelley',\n",
              " 'greenland',\n",
              " 'sacagawea',\n",
              " 'megan',\n",
              " 'shofar',\n",
              " 'wood',\n",
              " 'milan',\n",
              " 'barney',\n",
              " 'rockefeller',\n",
              " 'a satyr',\n",
              " 'rome',\n",
              " 'uncle sam',\n",
              " 'tripoli',\n",
              " 'ted',\n",
              " '(truman) capote',\n",
              " 'a crypt script',\n",
              " 'd.b. cooper',\n",
              " 'the powerpuff girls',\n",
              " 'oak ridge',\n",
              " 'talk soup',\n",
              " 'bread/dough',\n",
              " 'the love boat',\n",
              " 'venezuela',\n",
              " 'saxophone',\n",
              " 'george ryan',\n",
              " '\"stopping by woods on a snowy evening\"',\n",
              " 'the huguenots',\n",
              " '(charlie) rangel',\n",
              " 'thurston howell iii',\n",
              " 'valparaiso',\n",
              " 'wax',\n",
              " 'unicef',\n",
              " 'the godfather',\n",
              " 'billy idol',\n",
              " 'the cornea',\n",
              " 'the circle',\n",
              " 'gibraltar',\n",
              " 'daddy day care',\n",
              " 'howard stern',\n",
              " 'dr. benjamin spock',\n",
              " '(charles m.) barnes',\n",
              " 'familiar',\n",
              " 'bill russell',\n",
              " 'rock candy',\n",
              " 'barney clark',\n",
              " 'gold',\n",
              " 'devo',\n",
              " 'air & space museum',\n",
              " 'hyundai',\n",
              " 'mozart',\n",
              " '(lauren) bacall',\n",
              " 'russia',\n",
              " 'the congress party',\n",
              " 'evangeline',\n",
              " 'gullible',\n",
              " 'the origin of species',\n",
              " 'things that make you cry',\n",
              " 'people',\n",
              " 'i',\n",
              " 'governor',\n",
              " 'manhattan',\n",
              " 'france',\n",
              " 'tv guide',\n",
              " 'russo-japanese war',\n",
              " 'the hms beagle',\n",
              " 'chicken kiev',\n",
              " 'vanessa williams',\n",
              " 'wort',\n",
              " 'rocking (or swinging)',\n",
              " 'santa monica',\n",
              " 'swahili',\n",
              " 'decameron',\n",
              " \"mcdonald's\",\n",
              " 'ivan the terrible',\n",
              " 'quiz show',\n",
              " 'the vietnam war',\n",
              " 'hero',\n",
              " 'the time machine',\n",
              " 'jamboree',\n",
              " 'a furlong',\n",
              " 'crate & barrel',\n",
              " 'ernest hemingway',\n",
              " 'johannes gutenberg',\n",
              " 'paul bunyan',\n",
              " 'david copperfield',\n",
              " 'an icebreaker',\n",
              " 'the cia',\n",
              " 'george wallace',\n",
              " 'galileo',\n",
              " 'making a quilt',\n",
              " 'vassar',\n",
              " 'nachos',\n",
              " 'emu',\n",
              " 'the black box',\n",
              " 'the nile',\n",
              " 'tillamook',\n",
              " 'the nittany lions',\n",
              " 'aldous huxley',\n",
              " 'npr',\n",
              " 'quicksilver',\n",
              " 'leonardo da vinci',\n",
              " 'norway',\n",
              " 'william bradford',\n",
              " 'guy day',\n",
              " 'attorney general',\n",
              " 'great britain (united kingdom)',\n",
              " 'the appian way',\n",
              " 'i never promised you a rose garden',\n",
              " 'iceland',\n",
              " 'heel',\n",
              " \"that's incredible!\",\n",
              " 'sagas',\n",
              " 'alfred lord tennyson',\n",
              " 'minneapolis-st. paul',\n",
              " 'the big top',\n",
              " 'spartacus',\n",
              " 'the uv index',\n",
              " 'interview',\n",
              " 'mild & meld',\n",
              " 'japan',\n",
              " 'george washington carver',\n",
              " 'dr. benjamin spock (\\\\\"baby and child care\\\\\")',\n",
              " 'hercules',\n",
              " 'a siege',\n",
              " 'madagascar',\n",
              " 'xavier',\n",
              " 'the 1950s',\n",
              " 'a christmas carol',\n",
              " 'scott',\n",
              " '(samuel) morse',\n",
              " 'hawks',\n",
              " 'john deere',\n",
              " 'pusan',\n",
              " 'insulin',\n",
              " 'peter piper',\n",
              " 'a stepfather',\n",
              " '(things with) tails',\n",
              " 'the star-spangled banner',\n",
              " 'ensenada',\n",
              " 'a sword in the stone',\n",
              " 'bangkok',\n",
              " 'aretha franklin',\n",
              " 'da nang',\n",
              " 'the ground floor (or the ground level)',\n",
              " 'the tropic of capricorn',\n",
              " 'correct',\n",
              " 'karol wojtyla (pope john paul ii)',\n",
              " 'brains',\n",
              " 'the blind',\n",
              " '\"layla\"',\n",
              " 'tina turner',\n",
              " '(douglas) mcarthur',\n",
              " 'black hawk',\n",
              " 'john d. rockefeller',\n",
              " 'the coda',\n",
              " 'gabriel',\n",
              " 'don cornelius',\n",
              " 'hattie mcdaniel (for her role in gone with the wind)',\n",
              " 'oxygen',\n",
              " 'junket',\n",
              " 'blossoms',\n",
              " 'vatican city',\n",
              " 'corn',\n",
              " 'vanity fair',\n",
              " 'saturday night live',\n",
              " 'mccloud',\n",
              " 'united airlines',\n",
              " 'the tibia & fibula',\n",
              " 'die hard',\n",
              " 'barbara',\n",
              " 'proletariat',\n",
              " 'folsom',\n",
              " 'washington irving',\n",
              " 'hell week',\n",
              " 'john f. kennedy',\n",
              " 'pollen',\n",
              " 'eden',\n",
              " 'dish & spoon',\n",
              " 'jay leno',\n",
              " 'borders',\n",
              " 'syphilis',\n",
              " 'a lemon',\n",
              " 'india',\n",
              " 'mount everest',\n",
              " 'seattle',\n",
              " 'gale gordon',\n",
              " 'prostate cancer',\n",
              " \"charlie's angels\",\n",
              " 'b. traven',\n",
              " 'gaseous',\n",
              " 'esther williams',\n",
              " 'emily dickinson',\n",
              " 'powder',\n",
              " 'things that are over my head',\n",
              " 'michael',\n",
              " 'a lei & a lee',\n",
              " 'a molly',\n",
              " 'a bird',\n",
              " 'do-re-mi',\n",
              " 'madame dubarry',\n",
              " 'impressionism',\n",
              " 'a polygraph',\n",
              " 'mir',\n",
              " 'tudor',\n",
              " 'sarah jessica parker',\n",
              " 'red tape',\n",
              " 'kick',\n",
              " 'the river jordan',\n",
              " 'pius',\n",
              " 'samuel taylor coleridge',\n",
              " 'ireland',\n",
              " 'mourning',\n",
              " 'slip',\n",
              " 'portugal',\n",
              " 'a grader',\n",
              " 'jann wenner',\n",
              " 'hades',\n",
              " '\"hot lips\"',\n",
              " 'southwest',\n",
              " 'penguin',\n",
              " 'marlon brando',\n",
              " 'ayn rand',\n",
              " 'sweet',\n",
              " 'arthur fiedler',\n",
              " 'new york',\n",
              " 'magma',\n",
              " '(louis) pasteur',\n",
              " 'pins',\n",
              " 'phil silvers',\n",
              " 'a daddy long-legs',\n",
              " '\"song of roland\"',\n",
              " 'england',\n",
              " 'adolphus busch',\n",
              " 'rio grande',\n",
              " 'the bulldogs',\n",
              " 'finland',\n",
              " '\"damn yankees!\"',\n",
              " 'dalai lama',\n",
              " 'eric idle',\n",
              " 'queen isabella',\n",
              " '(edwin) hubble',\n",
              " 'norman mailer',\n",
              " 'stefano gabbana',\n",
              " 'elton john',\n",
              " 'larry bird',\n",
              " 'h2o',\n",
              " 'inconvenient',\n",
              " 'corsica',\n",
              " 'shoes',\n",
              " 'trimspa',\n",
              " 'vancouver',\n",
              " \"campbell's soup cans\",\n",
              " 'moroni',\n",
              " 'cochlear',\n",
              " 'on the waterfront',\n",
              " 'bucephalus',\n",
              " '(deepak) chopra',\n",
              " 'silly string',\n",
              " 'arctic ocean',\n",
              " 'dribbling',\n",
              " 'theodore roosevelt',\n",
              " 'casey kasem',\n",
              " 'socket',\n",
              " 'melbourne',\n",
              " 'an egg',\n",
              " 'jennifer',\n",
              " 'dronehenge',\n",
              " 'dionne warwick',\n",
              " 'a map',\n",
              " 'a dialysis machine',\n",
              " 'pants',\n",
              " 'red sea',\n",
              " \"mickey's hickeys\",\n",
              " 'grenadine',\n",
              " 'concord',\n",
              " 'the winds of war',\n",
              " 'the snake river',\n",
              " 'inversion',\n",
              " 'captain john smith',\n",
              " 'a longshoreman',\n",
              " 'the coast guard',\n",
              " '(john) updike',\n",
              " 'john mellencamp',\n",
              " 'athens',\n",
              " 'discovery',\n",
              " 'the world cup',\n",
              " 'howard hughes',\n",
              " 'never give a sucker an even break',\n",
              " 'short stories',\n",
              " 'polar bears',\n",
              " 'exceed',\n",
              " 'jonathan larson',\n",
              " 'philip kaufman',\n",
              " 'asteroids',\n",
              " 'canada',\n",
              " 'phil hartman',\n",
              " 'crane',\n",
              " '\"the threepenny opera\"',\n",
              " \"poor richard's almanack\",\n",
              " 'queen victoria',\n",
              " 'james worthy',\n",
              " 'ivan',\n",
              " 'w-2',\n",
              " 'n.y.p.d.',\n",
              " 'perestroika',\n",
              " 'abbie hoffman',\n",
              " 'michael jordan',\n",
              " 'manila',\n",
              " 'betsy ross',\n",
              " 'muscles',\n",
              " 'cotton mather',\n",
              " 'the epiphany',\n",
              " 'rainy season',\n",
              " '\"where\\'s charley?\"',\n",
              " 'time',\n",
              " 'corned beef',\n",
              " 'black',\n",
              " 'mummers',\n",
              " 'jenny jones',\n",
              " 'prizes',\n",
              " '\"we can work it out\"',\n",
              " 'joyce carol oates',\n",
              " 'three of a kind',\n",
              " 'libraries',\n",
              " 'the suez canal',\n",
              " 'colonel sanders',\n",
              " 'a pseudonym',\n",
              " '\"did i shave my legs for this?\"',\n",
              " 'tci (telecommunications, inc.)',\n",
              " 'mr. smith goes to washington',\n",
              " 'scratch',\n",
              " 'codeine',\n",
              " 'a mason',\n",
              " '(lou) gehrig',\n",
              " 'three mile island',\n",
              " 'missouri',\n",
              " 'stu sutcliffe',\n",
              " 'jakarta (indonesia)',\n",
              " '(st. ignatius) loyola',\n",
              " 'our town',\n",
              " 'battlestar galactica',\n",
              " 'tie',\n",
              " 'green gables',\n",
              " 'chock',\n",
              " 'joseph',\n",
              " 'plane',\n",
              " 'war',\n",
              " 'presbyterian',\n",
              " 'auguste rodin',\n",
              " \"pike's peak\",\n",
              " 'butter',\n",
              " 'red giants',\n",
              " 'a consommé',\n",
              " 'martha washington',\n",
              " 'karl marx',\n",
              " 'ellis island',\n",
              " 'groundhog day',\n",
              " 'wolfgang amadeus mozart',\n",
              " '\"deep throat\"',\n",
              " 'bode miller',\n",
              " 'city hall',\n",
              " 'mandible',\n",
              " 'truth or consequences (hot springs)',\n",
              " 'a slalom',\n",
              " 'the queen mary',\n",
              " 'sitcom',\n",
              " 'greece',\n",
              " 'barbra streisand',\n",
              " 'birthright',\n",
              " 'niagara falls',\n",
              " 'new hampshire',\n",
              " 'sony',\n",
              " 'a centimeter',\n",
              " 'the pheasant',\n",
              " 'red & white',\n",
              " 'judo',\n",
              " 'citigroup',\n",
              " 'puget sound',\n",
              " 'van',\n",
              " 'william and mary',\n",
              " 'zanzibar',\n",
              " 'transcontinental',\n",
              " 'calliope',\n",
              " 'iris',\n",
              " 'ted williams',\n",
              " 'justinian i',\n",
              " 'north carolina',\n",
              " \"high seas/c's\",\n",
              " 'the boston massacre',\n",
              " 't.j. hooker',\n",
              " 'nigeria',\n",
              " 'afro sheen',\n",
              " 'the gettysburg address',\n",
              " 'james baldwin',\n",
              " 'profanity',\n",
              " 'georgia frontiere',\n",
              " 'their genome',\n",
              " 'roast beef',\n",
              " 'oregon',\n",
              " 'trade winds',\n",
              " 'chestnuts',\n",
              " 'ruby ridge',\n",
              " 'jojo',\n",
              " 'the kiwi',\n",
              " 'fat man',\n",
              " 'smirk',\n",
              " 'chicken feed',\n",
              " 'robert frost',\n",
              " 'mall',\n",
              " 'kobe bryant',\n",
              " 'denmark',\n",
              " 'the 1940s',\n",
              " 'governess',\n",
              " 'china',\n",
              " 'anthracite',\n",
              " 'a clam',\n",
              " 'labrador retriever',\n",
              " 'why does anna karenina kill herself?',\n",
              " 'a palindrome',\n",
              " 'steve carell',\n",
              " 'musaka',\n",
              " 'the grapes of wrath',\n",
              " 'now',\n",
              " 'cape horn',\n",
              " 'leaves',\n",
              " 'old yeller',\n",
              " '\"funny girl\"',\n",
              " 'leo',\n",
              " 'an opera',\n",
              " 'cuba',\n",
              " 'lt. col. henry blake & col. sherman potter',\n",
              " 'clarinet',\n",
              " 'evelyn waugh',\n",
              " 'king hussein',\n",
              " '40th anniversary',\n",
              " 'the annunciation',\n",
              " 'pinata',\n",
              " 'the federalists',\n",
              " 'the ark of the covenant',\n",
              " 'isabella',\n",
              " 'rickey henderson',\n",
              " '(colin) powell',\n",
              " 'categorizing',\n",
              " 'greek',\n",
              " 'the west wing',\n",
              " 'sunni',\n",
              " 'cyd charisse',\n",
              " '\"suicide is painless\"',\n",
              " 'finding nemo',\n",
              " '\"it\\'s just a matter of time\"',\n",
              " 'the youngest person',\n",
              " 'nobelium',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "_fkvfWlCRykY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqMDMsKRSiZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}